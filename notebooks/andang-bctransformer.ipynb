{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BC-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_918210/2054253238.py:11: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(config_path='../libero/configs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'color_aug': { 'network': 'BatchWiseImgColorJitterAug',\n",
      "                 'network_kwargs': { 'brightness': 0.3,\n",
      "                                     'contrast': 0.3,\n",
      "                                     'epsilon': 0.1,\n",
      "                                     'hue': 0.3,\n",
      "                                     'input_shape': None,\n",
      "                                     'saturation': 0.3}},\n",
      "  'embed_size': 64,\n",
      "  'extra_hidden_size': 128,\n",
      "  'extra_num_layers': 0,\n",
      "  'image_encoder': { 'network': 'ResnetEncoder',\n",
      "                     'network_kwargs': { 'freeze': False,\n",
      "                                         'language_fusion': 'film',\n",
      "                                         'no_stride': False,\n",
      "                                         'pretrained': False,\n",
      "                                         'remove_layer_num': 4}},\n",
      "  'language_encoder': { 'network': 'MLPEncoder',\n",
      "                        'network_kwargs': { 'hidden_size': 128,\n",
      "                                            'input_size': 768,\n",
      "                                            'num_layers': 1,\n",
      "                                            'output_size': 128}},\n",
      "  'policy_head': { 'loss_kwargs': {'loss_coef': 1.0},\n",
      "                   'network': 'GMMHead',\n",
      "                   'network_kwargs': { 'activation': 'softplus',\n",
      "                                       'hidden_size': 1024,\n",
      "                                       'low_eval_noise': False,\n",
      "                                       'min_std': 0.0001,\n",
      "                                       'num_layers': 2,\n",
      "                                       'num_modes': 5}},\n",
      "  'policy_type': 'BCTransformerPolicy',\n",
      "  'temporal_position_encoding': { 'network': 'SinusoidalPositionEncoding',\n",
      "                                  'network_kwargs': { 'factor_ratio': None,\n",
      "                                                      'input_size': None,\n",
      "                                                      'inv_freq_factor': 10}},\n",
      "  'transformer_dropout': 0.1,\n",
      "  'transformer_head_output_size': 64,\n",
      "  'transformer_input_size': None,\n",
      "  'transformer_max_seq_len': 10,\n",
      "  'transformer_mlp_hidden_size': 256,\n",
      "  'transformer_num_heads': 6,\n",
      "  'transformer_num_layers': 4,\n",
      "  'translation_aug': { 'network': 'TranslationAug',\n",
      "                       'network_kwargs': { 'input_shape': None,\n",
      "                                           'translation': 8}}}\n"
     ]
    }
   ],
   "source": [
    "import hydra\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "from libero.libero import get_libero_path\n",
    "import pprint\n",
    "\n",
    "# load default hydra config\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(config_path='../libero/configs')\n",
    "hydra_cfg = compose(config_name=\"config\")\n",
    "yaml_config = OmegaConf.to_yaml(hydra_cfg)\n",
    "cfg = EasyDict(yaml.safe_load(yaml_config))\n",
    "\n",
    "# prepare lifelong learning\n",
    "cfg.folder = get_libero_path(\"datasets\")\n",
    "cfg.bddl_folder = get_libero_path(\"bddl_files\")\n",
    "cfg.init_states_folder = get_libero_path(\"init_states\")\n",
    "cfg.eval.num_procs = 1\n",
    "cfg.eval.n_eval = 5\n",
    "cfg.train.n_epochs = 25\n",
    "cfg.benchmark_name = \"libero_object\" # can be from {\"libero_spatial\", \"libero_object\", \"libero_goal\", \"libero_10\"}\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "pp.pprint(cfg.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "from libero.libero import benchmark\n",
    "from libero.libero.benchmark import get_benchmark\n",
    "\n",
    "task_order = cfg.data.task_order_index # can be from {0 .. 21}, default to 0, which is [task 0, 1, 2 ...]\n",
    "benchmark = get_benchmark(cfg.benchmark_name)(task_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: rgb with keys: ['agentview_rgb', 'eye_in_hand_rgb']\n",
      "using obs modality: depth with keys: []\n",
      "using obs modality: low_dim with keys: ['joint_states', 'gripper_states']\n",
      "SequenceDataset: loading dataset into memory...\n",
      "100%|██████████| 50/50 [00:00<00:00, 1749.96it/s]\n"
     ]
    }
   ],
   "source": [
    "from libero.lifelong.datasets import SequenceVLDataset, get_dataset\n",
    "from libero.lifelong.utils import get_task_embs\n",
    "import os\n",
    "# prepare datasets from the benchmark\n",
    "datasets = []\n",
    "descriptions = []\n",
    "n_tasks = benchmark.n_tasks #hopefully unused\n",
    "task_id = 0\n",
    "assert 0 <= task_id < n_tasks, f\"task_id {task_id} out of range [0, {n_tasks})\"\n",
    "N_DEMOS = None\n",
    "\n",
    "# currently we assume tasks from same benchmark have the same shape_meta\n",
    "task_id_dataset, shape_meta = get_dataset(\n",
    "        dataset_path=os.path.join(cfg.folder, benchmark.get_task_demonstration(task_id)),\n",
    "        obs_modality=cfg.data.obs.modality,\n",
    "        initialize_obs_utils=True,\n",
    "        seq_len=cfg.data.seq_len,\n",
    "        n_demos=N_DEMOS\n",
    ")\n",
    "# add language to the vision dataset, hence we call vl_dataset\n",
    "description = benchmark.get_task(task_id).language\n",
    "\n",
    "task_embs = get_task_embs(cfg, [description])\n",
    "benchmark.set_task_embs(task_embs)\n",
    "dataset = SequenceVLDataset(task_id_dataset, task_embs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[info] Epoch:   0 | train loss:  5.50 | time: 0.61\n",
      "[info] evaluate task 0 takes 125.0 seconds\n",
      "[info] Epoch:   0 | succ: 0.00 ± 0.00 | best succ: 0.0 | succ. AoC 0.00 | time: 2.08\n",
      "[info] Epoch:   1 | train loss: -7.33 | time: 1.63\n",
      "[info] Epoch:   2 | train loss: -12.79 | time: 1.18\n",
      "[info] Epoch:   3 | train loss: -14.31 | time: 1.12\n",
      "[info] Epoch:   4 | train loss: -15.05 | time: 1.11\n",
      "[info] Epoch:   5 | train loss: -15.49 | time: 1.10\n",
      "[info] evaluate task 0 takes 154.1 seconds\n",
      "[info] Epoch:   5 | succ: 0.00 ± 0.00 | best succ: 0.0 | succ. AoC 0.00 | time: 2.57\n",
      "[info] Epoch:   6 | train loss: -15.91 | time: 1.23\n",
      "[info] Epoch:   7 | train loss: -16.37 | time: 1.57\n",
      "[info] Epoch:   8 | train loss: -16.61 | time: 2.42\n",
      "[info] Epoch:   9 | train loss: -16.88 | time: 2.04\n",
      "[info] Epoch:  10 | train loss: -17.13 | time: 2.29\n",
      "[info] evaluate task 0 takes 185.4 seconds\n",
      "[info] Epoch:  10 | succ: 0.20 ± 0.35 | best succ: 0.2 | succ. AoC 0.07 | time: 3.09\n",
      "[info] Epoch:  11 | train loss: -17.40 | time: 2.84\n",
      "[info] Epoch:  12 | train loss: -17.69 | time: 2.93\n",
      "[info] Epoch:  13 | train loss: -17.89 | time: 2.16\n",
      "[info] Epoch:  14 | train loss: -18.12 | time: 1.28\n",
      "[info] Epoch:  15 | train loss: -18.30 | time: 1.76\n",
      "[info] evaluate task 0 takes 103.9 seconds\n",
      "[info] Epoch:  15 | succ: 0.80 ± 0.35 | best succ: 0.8 | succ. AoC 0.25 | time: 1.73\n",
      "[info] Epoch:  16 | train loss: -18.54 | time: 2.94\n",
      "[info] Epoch:  17 | train loss: -18.73 | time: 2.93\n",
      "[info] Epoch:  18 | train loss: -18.91 | time: 2.32\n",
      "[info] Epoch:  19 | train loss: -19.07 | time: 1.49\n",
      "[info] Epoch:  20 | train loss: -19.24 | time: 1.63\n",
      "[info] evaluate task 0 takes 65.9 seconds\n",
      "[info] Epoch:  20 | succ: 1.00 ± 0.00 | best succ: 1.0 | succ. AoC 0.40 | time: 1.10\n",
      "[info] Epoch:  21 | train loss: -19.37 | time: 2.95\n",
      "[info] Epoch:  22 | train loss: -19.05 | time: 2.57\n",
      "[info] Epoch:  23 | train loss: -19.54 | time: 2.29\n",
      "[info] Epoch:  24 | train loss: -19.63 | time: 2.90\n",
      "[info] Epoch:  25 | train loss: -19.71 | time: 2.86\n",
      "[info] evaluate task 0 takes 76.8 seconds\n",
      "[info] Epoch:  25 | succ: 1.00 ± 0.00 | best succ: 1.0 | succ. AoC 0.50 | time: 1.28\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import robomimic.utils.tensor_utils as TensorUtils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from libero.lifelong.algos.single_task import SingleTask\n",
    "from libero.lifelong.utils import safe_device, create_experiment_dir\n",
    "\n",
    "\n",
    "cfg.policy.policy_type = 'BCTransformerPolicy'\n",
    "cfg.lifelong.algo = 'SingleTask'\n",
    "create_experiment_dir(cfg)\n",
    "cfg.shape_meta = shape_meta\n",
    "\n",
    "algo = safe_device(SingleTask(n_tasks, cfg), cfg.device)\n",
    "\n",
    "# unused variable\n",
    "import numpy as np\n",
    "result_summary = {\n",
    "    'L_conf_mat': np.zeros((n_tasks, n_tasks)),   # loss confusion matrix\n",
    "    'S_conf_mat': np.zeros((n_tasks, n_tasks)),   # success confusion matrix\n",
    "    'L_fwd'     : np.zeros((n_tasks,)),           # loss AUC, how fast the agent learns\n",
    "    'S_fwd'     : np.zeros((n_tasks,)),           # success AUC, how fast the agent succeeds\n",
    "}\n",
    "\n",
    "# succ is from evaluation / rollout on the task\n",
    "algo.train()\n",
    "succ_fwd, loss_fwd = algo.learn_one_task(dataset, 0, benchmark, result_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "import imageio\n",
    "import cv2\n",
    "from libero.libero.envs import OffScreenRenderEnv, DummyVectorEnv\n",
    "from libero.lifelong.metric import raw_obs_to_tensor_obs\n",
    "\n",
    "# You can turn on subprocess\n",
    "env_num = 1\n",
    "action_dim = 7\n",
    "\n",
    "# If it's packnet, the weights need to be processed first\n",
    "task = benchmark.get_task(task_id)\n",
    "task_emb = benchmark.get_task_emb(task_id)\n",
    "if cfg.lifelong.algo == \"PackNet\":\n",
    "    algo = algo.get_eval_algo(task_id)\n",
    "\n",
    "algo.eval()\n",
    "env_args = {\n",
    "    \"bddl_file_name\": os.path.join(\n",
    "        cfg.bddl_folder, task.problem_folder, task.bddl_file\n",
    "    ),\n",
    "    \"camera_heights\": cfg.data.img_h,\n",
    "    \"camera_widths\": cfg.data.img_w,\n",
    "}\n",
    "\n",
    "env = DummyVectorEnv(\n",
    "            [lambda: OffScreenRenderEnv(**env_args) for _ in range(env_num)]\n",
    ")\n",
    "\n",
    "init_states_path = os.path.join(\n",
    "    cfg.init_states_folder, task.problem_folder, task.init_states_file\n",
    ")\n",
    "init_states = torch.load(init_states_path)\n",
    "\n",
    "env.reset()\n",
    "\n",
    "init_state = init_states[0:1]\n",
    "dones = [False]\n",
    "\n",
    "algo.reset()\n",
    "\n",
    "obs = env.set_init_state(init_state)\n",
    "\n",
    "# Make sure the gripepr is open to make it consistent with the provided demos.\n",
    "dummy_actions = np.zeros((env_num, action_dim))\n",
    "for _ in range(5):\n",
    "    obs, _, _, _ = env.step(dummy_actions)\n",
    "\n",
    "steps = 0\n",
    "\n",
    "obs_tensors = [[]] * env_num\n",
    "while steps < cfg.eval.max_steps:\n",
    "    steps += 1\n",
    "    data = raw_obs_to_tensor_obs(obs, task_emb, cfg)\n",
    "    action = algo.policy.get_action(data)\n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "    for k in range(env_num):\n",
    "        dones[k] = dones[k] or done[k]\n",
    "        obs_tensors[k].append(obs[k][\"agentview_image\"])\n",
    "    if all(dones):\n",
    "        break\n",
    "    \n",
    "# visualize video\n",
    "# obs_tensor: (env_num, T, H, W, C)\n",
    "\n",
    "images = [img[::-1] for img in obs_tensors[0]]\n",
    "fps = 30\n",
    "writer  = imageio.get_writer('tmp_video.mp4', fps=fps)\n",
    "for image in images:\n",
    "    # resize image to 640x640\n",
    "    image = cv2.resize(image, (640, 640))\n",
    "    writer.append_data(image)\n",
    "writer.close()\n",
    "\n",
    "video_data = open(\"tmp_video.mp4\", \"rb\").read()\n",
    "video_tag = f'<video controls alt=\"test\" src=\"data:video/mp4;base64,{b64encode(video_data).decode()}\">'\n",
    "HTML(data=video_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
